{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d53b3aa-6a64-4f6a-9f57-d96c06ff0ee0",
   "metadata": {},
   "source": [
    "# differential-expression-analysis-lupine\n",
    "8.12.24\n",
    "\n",
    "Our standard differential expression analysis workflow, ensuring a 1-to-1 comparison of Lupine, Dream and naive imputation. Here we're getting DE imputed proteins after Lupine impute. \n",
    "\n",
    "Need to make sure that we're comparing the same proteins across all three of these notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43326d28-db93-4ed9-925e-caf619bf4163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "from scipy import stats\n",
    "from adjustText import adjust_text\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plotting templates\n",
    "sns.set(context=\"talk\", style=\"ticks\") \n",
    "pal = sns.color_palette(\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb6e19a-aae5-49a0-945f-8cd00b8af387",
   "metadata": {},
   "source": [
    "#### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c87f6215-3540-44d6-94b4-97d28a23964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unimputed joint quants matrix\n",
    "joint_fname=\"/net/noble/vol2/home/lincolnh/data/quant-data/UMich-normalized/joint-quants-normalized-shifted.csv\"\n",
    "min_pres=18\n",
    "\n",
    "# The Lupine recon matrix\n",
    "lupine_recon_ensembled_path=\"/net/noble/vol2/home/lincolnh/code/2023_harris_deep_impute/results/2024-05-30_DE_sandbox/results/lupine-ensemble-imputed.csv\"\n",
    "\n",
    "# The Ensemble (GENCODEv44) fasta\n",
    "ensembl_path=\"/net/noble/vol2/home/lincolnh/code/2023_harris_deep_impute/results/2023-11-13_UMich_dataset/fastas/\"\n",
    "ensembl_df=\"gencode.v44.pc_translations.fa\"\n",
    "\n",
    "# The HGNC database file\n",
    "hgnc_database_path=\"/net/noble/vol2/home/lincolnh/data/quant-data/HGNC_database.txt\"\n",
    "\n",
    "# The metadata dictionary, previously created\n",
    "meta_path=\"/net/noble/vol2/home/lincolnh/code/2023_harris_deep_impute/results/2024-05-10_metadata_mapping/meta-dict.csv\"\n",
    "\n",
    "cohort_ids=[\"BRCA\", \"CCRCC\", \"COAD\", \"GBM\", \"HGSC\", \n",
    "            \"HNSCC\", \"LSCC\", \"LUAD\", \"PDAC\", \"UCEC\"]\n",
    "\n",
    "# Set the thresholds\n",
    "adjusted_alpha=1e-2\n",
    "fc_thresh=0.5\n",
    "pres_frac_thresh=0.5 # Default here is 50%\n",
    "\n",
    "curr_cohort = \"CCRCC\"\n",
    "\n",
    "rng = np.random.default_rng(seed=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa371a70-e61e-497c-b286-3fe30ad76f44",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e295ef2-11d4-45fd-8039-b11b956c4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bh_adjustment(pvals):\n",
    "    \"\"\"\n",
    "    Performs the Benjamini-Hochberg procedure\n",
    "    for p-value ADJUSTMENT. So this means we actually \n",
    "    return a list of corrected p-values, not just a \n",
    "    boolean specifying which p-values to keep per the\n",
    "    FDR controlled at some threshold. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pvals : np.ndarray, \n",
    "        The sorted list of uncorrected p-values. Sorted\n",
    "        from smallest to largest\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    pvals_adjusted : list, \n",
    "        A list of the BH adjusted p-values\n",
    "    \"\"\"\n",
    "    pvals_adjusted = []\n",
    "\n",
    "    for i in range(0, len(pvals)):\n",
    "        rank = i + 1\n",
    "        curr_pval = pvals[i]\n",
    "        pval_adj = (curr_pval * len(pvals)) / rank\n",
    "        pvals_adjusted.append(pval_adj)        \n",
    "\n",
    "    return pvals_adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35088f07-c311-4231-ab22-6fc2d7064669",
   "metadata": {},
   "source": [
    "#### Subset the metadata to a single cohort, get the tumor and nontumor sample IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2d84e0-6c0e-47f5-b4f3-e09b917f99e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "# Might need `index_col=0` here\n",
    "meta_dict = pd.read_csv(meta_path)\n",
    "meta_dict = meta_dict[meta_dict[\"cohort\"] == curr_cohort]\n",
    "meta_dict = meta_dict.reset_index(drop=True)\n",
    "\n",
    "tumor_samples_meta = meta_dict[(meta_dict[\"sample_type\"] == \"Primary Tumor\") | (meta_dict[\"sample_type\"] == \"Tumor\")]\n",
    "nontumor_samples_meta = meta_dict[(meta_dict[\"sample_type\"] != \"Primary Tumor\") & (meta_dict[\"sample_type\"] != \"Tumor\")]\n",
    "\n",
    "tumor_IDs = list(tumor_samples_meta[\"aliquot_ID\"])\n",
    "nontumor_IDs = list(nontumor_samples_meta[\"aliquot_ID\"])\n",
    "\n",
    "print(len(tumor_IDs))\n",
    "print(len(nontumor_IDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb425c05-2c9b-426a-928a-9a79c394fd9a",
   "metadata": {},
   "source": [
    "#### Pre-process the unimputed joint quants matrix\n",
    "This should get us to the exact same starting point as the Lupine ensemble impute procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aef92b5-9b2f-460f-b48d-1e3ef118a2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint quants mat shape, post-filter: (18162, 1755)\n"
     ]
    }
   ],
   "source": [
    "# Read in the joint quants matrix\n",
    "joint_mat = pd.read_csv(joint_fname, index_col=0)\n",
    "\n",
    "# Remove some of these extraneous runs\n",
    "keywords = [\"RefInt\", \"QC\", \"pool\", \"Tumor\", \"Pooled\", \n",
    "            \"Pool\", \"Reference\", \"NCI\", \"NX\", \"Ref\"]\n",
    "to_drop = []\n",
    "\n",
    "for sample_id in list(joint_mat.columns):\n",
    "    exclude=False\n",
    "    for kw in keywords:\n",
    "        if kw in sample_id:\n",
    "            exclude=True\n",
    "            break\n",
    "    to_drop.append(exclude)\n",
    "\n",
    "keep_cols = np.array(joint_mat.columns)[~np.array(to_drop)]\n",
    "joint_mat = joint_mat[keep_cols]\n",
    "\n",
    "joint = np.array(joint_mat)\n",
    "\n",
    "# Remove proteins with too many missing values\n",
    "num_present = np.sum(~np.isnan(joint), axis=1)\n",
    "discard = num_present < min_pres\n",
    "joint = np.delete(joint, discard, axis=0)\n",
    "keep_prots = np.array(joint_mat.index)[~discard]\n",
    "\n",
    "print(f\"joint quants mat shape, post-filter: {joint.shape}\")\n",
    "\n",
    "joint_start = pd.DataFrame(joint, columns=keep_cols, index=keep_prots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c1a6e-6e5f-4417-9f65-2d43319f6009",
   "metadata": {},
   "source": [
    "#### Remove the proteins with >50% missingness\n",
    "From the unimputed runs corresponding to the current cohort. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af743c6c-d6fb-449d-b161-65dd00187e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9324, 194)\n"
     ]
    }
   ],
   "source": [
    "cohort_quants_start = joint_start[tumor_IDs + nontumor_IDs]\n",
    "\n",
    "num_present = np.sum(~np.isnan(cohort_quants_start), axis=1)\n",
    "pres_fracs = num_present / cohort_quants_start.shape[1]\n",
    "\n",
    "cohort_quants_start = cohort_quants_start[pres_fracs >= pres_frac_thresh]\n",
    "print(cohort_quants_start.shape)\n",
    "\n",
    "keep_prots_cohort = list(cohort_quants_start.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e8c852-3c2b-45d3-95da-824281c08249",
   "metadata": {},
   "source": [
    "#### Read in the Lupine imputed quants and subset by initial missingness fraction\n",
    "And subset by the DreamAI imputed proteins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b8338cd-84c9-4088-ad0c-5ca591992d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9324, 1755)\n"
     ]
    }
   ],
   "source": [
    "lupine_recon = pd.read_csv(lupine_recon_ensembled_path, index_col=0)\n",
    "lupine_recon = lupine_recon.loc[keep_prots_cohort]\n",
    "print(lupine_recon.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19153bd5-733c-4e1f-b4d2-a08c6557bb21",
   "metadata": {},
   "source": [
    "#### Exponentiate to get the original, untransformed intensities\n",
    "These quants had previously been log2 transformed (by the CPTAC project). So we're inversing that transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df014c58-1426-4353-b1e6-34a6d4a99da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_start = np.power(2, joint_start)\n",
    "lupine_recon = np.power(2, lupine_recon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675a237-c90b-4f11-9f83-b867a4089631",
   "metadata": {},
   "source": [
    "#### Get quants matrices for tumor and non-tumor samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6050909e-af1c-454a-8033-7a03c57745e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9324, 110)\n",
      "(9324, 84)\n"
     ]
    }
   ],
   "source": [
    "tumor_quants = lupine_recon[tumor_IDs]\n",
    "nontumor_quants = lupine_recon[nontumor_IDs]\n",
    "\n",
    "tumor_mat = np.array(tumor_quants)\n",
    "nontumor_mat = np.array(nontumor_quants)\n",
    "\n",
    "print(tumor_mat.shape)\n",
    "print(nontumor_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d103809-7dec-47fe-bab1-33a557ccca5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.98134978,  26.44337243,  27.74742216, ...,  10.92968291,\n",
       "         10.73320937,  27.86835297],\n",
       "       [ 16.32525131,  28.64254146,  15.75339449, ...,  30.83368201,\n",
       "         29.61953104,  14.69317431],\n",
       "       [ 45.4331752 ,  43.33833384,  36.40943748, ...,  47.46637244,\n",
       "         49.10734399,  46.83520953],\n",
       "       ...,\n",
       "       [409.23707725, 438.87552164, 343.56423355, ..., 476.51369211,\n",
       "        529.12305672, 487.42568685],\n",
       "       [139.72580923, 147.23765458, 118.97014981, ..., 158.75071205,\n",
       "        135.09557892, 154.06654625],\n",
       "       [ 96.96327335, 101.92839175, 100.53503768, ..., 102.71271949,\n",
       "         99.89147753, 100.34169302]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nontumor_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9721c6-4470-4eb9-ae92-897803919701",
   "metadata": {},
   "source": [
    "#### Calculate the Wilcoxon-rank sum statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5583b92a-8761-4086-b6ae-614af0f30a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = []\n",
    "rs_stats = []\n",
    "\n",
    "for i in range(0, tumor_mat.shape[0]):\n",
    "    stat, pval = stats.ranksums(tumor_mat[i], nontumor_mat[i], nan_policy=\"omit\")\n",
    "    pvals.append(pval)\n",
    "    rs_stats.append(stat)\n",
    "\n",
    "# Init a dataframe to hold the p-values and adjusted p-values\n",
    "stats_df = pd.DataFrame(columns = [\"ENSP\", \"pval\", \"adj_pval\", \"orig_idx\"])\n",
    "stats_df[\"ENSP\"] = list(tumor_quants.index)\n",
    "stats_df[\"pval\"] = pvals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ceb9ae-52c6-4df8-8c29-c84e56397cf0",
   "metadata": {},
   "source": [
    "#### Do the Benjamini-Hochberg correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0874acf7-f7f4-4b95-a41a-d2c78395c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by uncorrected p-values\n",
    "stats_df = stats_df.sort_values(by=\"pval\")\n",
    "# Do the BH adjustment\n",
    "pvals_corrected = bh_adjustment(np.array(stats_df[\"pval\"]))\n",
    "stats_df[\"adj_pval\"] = pvals_corrected\n",
    "stats_df[\"orig_idx\"] = list(stats_df.index)\n",
    "\n",
    "# Return to the initial order\n",
    "stats_df = stats_df.sort_values(by=\"orig_idx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6257fe-6c73-4898-8705-54350ebee58f",
   "metadata": {},
   "source": [
    "#### Get the log fold changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54aa397f-5f84-4f89-8356-c3af1ebe35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_expr_means = np.nanmean(tumor_mat, axis=1)\n",
    "nontumor_expr_means = np.nanmean(nontumor_mat, axis=1)\n",
    "\n",
    "log_fold_changes = np.log2(tumor_expr_means / nontumor_expr_means)\n",
    "\n",
    "fdr = -np.log10(np.array(stats_df[\"adj_pval\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21091bb-4267-413b-8616-0f85317b796b",
   "metadata": {},
   "source": [
    "#### Create an aggregated dataframe for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4455c207-7261-453a-827b-5b222c0212e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = pd.DataFrame(columns=[\"ENSP\", \"HGNC\", \"p-value\", \"FC\"])\n",
    "aggregated[\"ENSP\"] = list(tumor_quants.index)\n",
    "aggregated[\"p-value\"] = np.array(stats_df[\"adj_pval\"])\n",
    "aggregated[\"FC\"] = log_fold_changes\n",
    "aggregated[\"FDR\"] = fdr\n",
    "#aggregated.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ed9e2-66d8-4574-a93d-50c0fc6dcbea",
   "metadata": {},
   "source": [
    "#### Create a dictionary mapping ENSPs to HGNCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99748453-3e1a-4d93-9cb3-a435db82209e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1910360/1917651185.py:2: DtypeWarning: Columns (31,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  hgnc_db = pd.read_csv(hgnc_database_path, sep=\"\\t\")\n"
     ]
    }
   ],
   "source": [
    "# Read in the HGNC database file\n",
    "hgnc_db = pd.read_csv(hgnc_database_path, sep=\"\\t\")\n",
    "\n",
    "# Read in the ENSEMBL fasta\n",
    "ensembl_fasta = ensembl_path + ensembl_df\n",
    "fasta_seqs = SeqIO.parse(open(ensembl_fasta), \"fasta\")\n",
    "\n",
    "# Init both dictionaries\n",
    "gene_x_prot = {}\n",
    "prot_x_gene = {}\n",
    "\n",
    "# Fill in the dictionary \n",
    "for fasta in fasta_seqs:\n",
    "    name, descript, sequence = \\\n",
    "        fasta.id, fasta.description, str(fasta.seq)\n",
    "    # Get the ENSP and ENSG IDs\n",
    "    ensp_id = name.split(\"|\")[0]\n",
    "    ensg_id = name.split(\"|\")[2]\n",
    "    # Strip the \".x\" characters. Hope this is ok.\n",
    "    ensp_id = ensp_id.split(\".\")[0]\n",
    "    ensg_id = ensg_id.split(\".\")[0]\n",
    "    \n",
    "    # Update the first dictionary\n",
    "    prot_x_gene[ensp_id] = ensg_id\n",
    "    \n",
    "    # Update the second\n",
    "    if ensg_id in gene_x_prot:\n",
    "        gene_x_prot[ensg_id].append(ensp_id)\n",
    "    else:\n",
    "        gene_x_prot[ensg_id] = [ensp_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b4474-ed8c-46c1-8b87-d47eb95403fe",
   "metadata": {},
   "source": [
    "#### Append the HGNC IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09ac46d0-ade4-4d63-9ede-0f1e8abe1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(0, aggregated.shape[0]):\n",
    "    curr = aggregated.iloc[idx]\n",
    "    curr_ensp = curr[\"ENSP\"]\n",
    "    try:\n",
    "        curr_ensg = prot_x_gene[curr_ensp]\n",
    "    except KeyError:\n",
    "        curr_ensg = None\n",
    "\n",
    "    # Add the ENSG ID\n",
    "    aggregated.loc[idx, \"ENSG\"] = curr_ensg\n",
    "\n",
    "    # Add in the HGNC gene ID as well \n",
    "    if curr_ensg is not None:\n",
    "        try:\n",
    "            hgnc_row = hgnc_db[hgnc_db[\"ensembl_gene_id\"] == curr_ensg]\n",
    "            hgnc_id = hgnc_row[\"symbol\"].item()\n",
    "\n",
    "            aggregated.loc[idx, \"HGNC\"] = hgnc_id\n",
    "        except ValueError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8b4ed9-c54a-4d57-a1a5-e26eeab1290d",
   "metadata": {},
   "source": [
    "#### Define up- and down-regulated genes/proteins \n",
    "According to our adjusted p-value threshold and log FC threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7f990a3-bc97-4c3c-bb57-0d0f94fce9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num up-reg: 102\n",
      "num down-reg: 462\n"
     ]
    }
   ],
   "source": [
    "up_df = aggregated[(aggregated[\"p-value\"] < adjusted_alpha) & (aggregated[\"FC\"] >= fc_thresh)]\n",
    "down_df = aggregated[(aggregated[\"p-value\"] < adjusted_alpha) & (aggregated[\"FC\"] <= -fc_thresh)]\n",
    "\n",
    "print(f\"num up-reg: {up_df.shape[0]}\")\n",
    "print(f\"num down-reg: {down_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c729b5a7-05bc-4853-8832-b9d2449f100d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PARVG',\n",
       " 'LOX',\n",
       " 'POSTN',\n",
       " 'ABCG1',\n",
       " 'NUPR1',\n",
       " 'POSTN',\n",
       " 'APBB1IP',\n",
       " 'ADAMTS7',\n",
       " 'GPX8',\n",
       " 'LOXL2',\n",
       " 'TNFAIP6',\n",
       " 'CDH4',\n",
       " 'ARHGAP22',\n",
       " 'GBP2',\n",
       " 'ANGPTL4',\n",
       " 'SLC2A1',\n",
       " 'NNMT',\n",
       " 'EPX',\n",
       " 'INTU',\n",
       " 'HK2',\n",
       " 'GYPA',\n",
       " 'SEMA5B',\n",
       " 'HAVCR1',\n",
       " 'PLOD2',\n",
       " 'FCER1G',\n",
       " 'SLC2A3',\n",
       " 'LAIR1',\n",
       " 'IKBIP',\n",
       " 'PFKP',\n",
       " nan,\n",
       " 'GBP5',\n",
       " 'SCARB1',\n",
       " 'FCGR3A',\n",
       " 'CTHRC1',\n",
       " 'IDO1',\n",
       " 'SCGN',\n",
       " 'TMSB10',\n",
       " 'HLA-DQB2',\n",
       " 'POSTN',\n",
       " 'IL32',\n",
       " 'PNCK',\n",
       " 'HAPLN1',\n",
       " 'SLC4A1',\n",
       " 'SLC16A3',\n",
       " 'FTH1',\n",
       " 'CAV1',\n",
       " 'ANGPT2',\n",
       " 'FHL1',\n",
       " 'P4HA2',\n",
       " 'P4HA1',\n",
       " 'TYMP',\n",
       " 'ALOX5',\n",
       " nan,\n",
       " 'ENO2',\n",
       " 'ENPP3',\n",
       " 'LPCAT1',\n",
       " 'EMILIN2',\n",
       " 'SPTA1',\n",
       " 'ITGB2',\n",
       " 'CYP2J2',\n",
       " 'IKBIP',\n",
       " 'SLC43A3',\n",
       " 'BTN3A2',\n",
       " 'PLIN2',\n",
       " 'SDS',\n",
       " 'C4orf3',\n",
       " 'ALB',\n",
       " 'TYROBP',\n",
       " nan,\n",
       " 'ITGAX',\n",
       " 'SIRPA',\n",
       " 'ANXA4',\n",
       " 'TMEM243',\n",
       " 'CD70',\n",
       " 'PDK1',\n",
       " 'CYBB',\n",
       " 'AHNAK2',\n",
       " 'ESM1',\n",
       " 'TGM2',\n",
       " 'NT5DC3',\n",
       " 'FABP6',\n",
       " 'CA9',\n",
       " 'COL23A1',\n",
       " 'MFSD13A',\n",
       " 'THBS2',\n",
       " 'FABP7',\n",
       " 'SCD',\n",
       " 'NCK1',\n",
       " 'NDUFA4L2',\n",
       " 'HBE1',\n",
       " 'RAB42',\n",
       " 'SPATA18',\n",
       " 'P2RX7',\n",
       " 'H1-5',\n",
       " 'CCND1',\n",
       " 'PYGL',\n",
       " 'POSTN',\n",
       " nan,\n",
       " 'SPATA18',\n",
       " 'PNMA2',\n",
       " 'FTL',\n",
       " 'BIRC3']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(up_df[\"HGNC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb0666a-b1bb-4758-92fd-7b68223321b0",
   "metadata": {},
   "source": [
    "---\n",
    "## Get volcano plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde61374-3096-4086-867f-df04f86a93f2",
   "metadata": {},
   "source": [
    "#### Create a dictionary to hold the top 10 DE proteins from the Savage et al., 2024 publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ead950f6-2413-4284-9f70-9373721f45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrcc_top10 = [\"TBXAS1\", \"PKN1\", \"PYGL\", \"P4HB\", \"ITGA5\", \"PPAT\", \"CAD\", \"TRIO\", \"LDHA\", \"ACLY\"]\n",
    "luad_top10 = [\"P4HB\", \"LDHA\", \"CDK12\", \"RANBP2\", \"SF3B1\", \"WDR5\", \"TOP1\", \"IARS1\", \"LARS1\", \"EEF2\"]\n",
    "coad_top10 = [\"HSP90AB1\", \"CAD\", \"SLC3A2\", \"RANBP2\", \"PRPF4B\", \"TOP1\", \"SF3B1\", \"IARS1\", \"MARS1\", \"TOP2A\"]\n",
    "hgsc_top10 = [\"ERP44\", \"APEX1\", \"HSP90AB1\", \"HSP90AA1\", \"PARP1\", \"TOP1\", \"HSP90B1\", \"MARS1\", \"IARS1\" \"SF3B1\"]\n",
    "hnscc_top10 = [\"PTK7\", \"SLC38A1\", \"PTPN12\", \"FKBP9\", \"PAK2\", \"ITPR3\", \"PTPN1\", \"NMT1\", \"ATP6V1C1\", \"TOP1\"]\n",
    "pdac_top10 = [\"ITGB4\", \"QSOX1\", \"ITPR3\", \"MET\", \"AEBP1\", \"NUCB1\", \"ITGAV\", \"LDHA\", \"GRK2\", \"LGALS3BP\"]\n",
    "lscc_top10 = [\"GART\", \"CAD\", \"PARP1\", \"PPAT\", \"CDK12\", \"TOP1\", \"CDK9\", \"SF3B1\", \"EEF2\", \"RRM2\"]\n",
    "ucec_top10 = [\"TACSTD2\", \"PIK3CB\", \"IL4I1\", \"KDM3A\", \"PPIF\", \"PTPRF\", \"PAK1\", \"IDE\", \"CSNK1A1\", \"MARS1\"]\n",
    "\n",
    "savage_mapper = {}\n",
    "\n",
    "savage_mapper[\"CCRCC\"] = ccrcc_top10\n",
    "savage_mapper[\"LUAD\"] = luad_top10\n",
    "savage_mapper[\"COAD\"] = coad_top10\n",
    "savage_mapper[\"HGSC\"] = hgsc_top10\n",
    "savage_mapper[\"HNSCC\"] = hnscc_top10\n",
    "savage_mapper[\"PDAC\"] = pdac_top10\n",
    "savage_mapper[\"LSCC\"] = lscc_top10\n",
    "savage_mapper[\"UCEC\"] = ucec_top10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ab65d8-7a2c-4b71-8442-4b1c92a6192d",
   "metadata": {},
   "source": [
    "#### Generate volcano plot\n",
    "And try to add in text labels for each of the genes of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12f5a655-3fc5-4eb6-b7b8-24f0169bad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "\n",
    "# # Get the base scatter plot\n",
    "# sns.scatterplot(\n",
    "#     data=aggregated,\n",
    "#     x=\"FC\", \n",
    "#     y=\"FDR\", \n",
    "#     alpha=0.1, \n",
    "#     linewidth=0.1,\n",
    "#     color=\"#7f7f7f\",\n",
    "#     ax=ax,\n",
    "# )\n",
    "# # Add the up-regulated proteins\n",
    "# sns.scatterplot(\n",
    "#     data=up_df,\n",
    "#     x=\"FC\", \n",
    "#     y=\"FDR\", \n",
    "#     alpha=0.75, \n",
    "#     linewidth=0.1,\n",
    "#     color=\"#ff7f0e\",\n",
    "#     ax=ax\n",
    "# )\n",
    "# # Add the down-regulated proteins\n",
    "# sns.scatterplot(\n",
    "#     data=down_df,\n",
    "#     x=\"FC\", \n",
    "#     y=\"FDR\", \n",
    "#     alpha=0.75, \n",
    "#     linewidth=0.1,\n",
    "#     color=\"#1f77b4\",\n",
    "#     ax=ax\n",
    "# )\n",
    "# # Add the gene IDs\n",
    "# for idx, row in aggregated.iterrows():\n",
    "#     if row[\"HGNC\"] in savage_mapper[curr_cohort]:\n",
    "#         xcoord_shift = row[\"FC\"] * 0.8 * rng.random()\n",
    "#         ycoord_shift = row[\"FDR\"] * 0.2 * rng.random()\n",
    "        \n",
    "#         xcoord_multiplier = rng.choice([-1,1])\n",
    "#         ycoord_multiplier = rng.choice([-1,1])\n",
    "    \n",
    "#         xcoord_shift = xcoord_shift * xcoord_multiplier\n",
    "#         ycoord_shift = ycoord_shift * ycoord_multiplier\n",
    "        \n",
    "#         ax.annotate(\n",
    "#             text=row[\"HGNC\"], \n",
    "#             xy=(row[\"FC\"], row[\"FDR\"]), \n",
    "#             xytext=(row[\"FC\"]+xcoord_shift, row[\"FDR\"]+ycoord_shift), \n",
    "#             fontsize=10, \n",
    "#             #bbox=dict(boxstyle=\"round\", alpha=0.1),\n",
    "#             arrowprops=dict(facecolor=\"#9467bd\", shrink=0.01, width=3, headwidth=8, headlength=4),\n",
    "#         )\n",
    "# ax.set_title(curr_cohort, pad=16, size=24)\n",
    "# ax.set_xlabel(\"log(FC)\", labelpad=10)\n",
    "# ax.set_ylabel(\"-log(p-value)\", labelpad=10)\n",
    "\n",
    "# ax.axvline(fc_thresh ,color=\"black\", linestyle=\"--\", alpha=0.4)\n",
    "# ax.axvline(-fc_thresh ,color=\"black\", linestyle=\"--\", alpha=0.4)\n",
    "# ax.axhline(5, color=\"black\", linestyle=\"--\", alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b64885-b887-4a93-82f9-70e99e69076c",
   "metadata": {},
   "source": [
    "#### Try with the `adjustText` package\n",
    "This might be what we want! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c5cd466-4ae9-459e-8e4a-7b0ce6a177c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "\n",
    "# # Get the base scatter plot\n",
    "# sns.scatterplot(\n",
    "#     data=aggregated,\n",
    "#     x=\"FC\", \n",
    "#     y=\"FDR\", \n",
    "#     alpha=0.1, \n",
    "#     linewidth=0.1,\n",
    "#     color=\"#7f7f7f\",\n",
    "#     ax=ax,\n",
    "# )\n",
    "# # Add the up-regulated proteins\n",
    "# sns.scatterplot(\n",
    "#     data=up_df,\n",
    "#     x=\"FC\", \n",
    "#     y=\"FDR\", \n",
    "#     alpha=0.9, \n",
    "#     linewidth=0.1,\n",
    "#     color=\"#ff7f0e\",\n",
    "#     ax=ax\n",
    "# )\n",
    "# # Add the down-regulated proteins\n",
    "# sns.scatterplot(\n",
    "#     data=down_df,\n",
    "#     x=\"FC\", \n",
    "#     y=\"FDR\", \n",
    "#     alpha=0.9, \n",
    "#     linewidth=0.1,\n",
    "#     color=\"#1f77b4\",\n",
    "#     ax=ax\n",
    "# )\n",
    "# labels = []\n",
    "# for idx, row in aggregated.iterrows():\n",
    "#     if row[\"HGNC\"] in savage_mapper[curr_cohort]:\n",
    "#         x_coord = row[\"FC\"]\n",
    "#         y_coord = row[\"FDR\"]\n",
    "#         labels.append(ax.text(x_coord, y_coord, s=row[\"HGNC\"], fontsize=10))\n",
    "\n",
    "# adjust_text(labels, arrowprops=dict(arrowstyle='-', lw=1.5, color=\"#9467bd\"))\n",
    "\n",
    "# ax.set_title(curr_cohort, pad=16, size=24)\n",
    "# ax.set_xlabel(\"log2 FC\", labelpad=10)\n",
    "# ax.set_ylabel(\"-log10 p-value\", labelpad=10)\n",
    "# #ax.set_ylabel(\"\")\n",
    "\n",
    "# ax.axvline(fc_thresh ,color=\"black\", linestyle=\"--\", alpha=0.4)\n",
    "# ax.axvline(-fc_thresh ,color=\"black\", linestyle=\"--\", alpha=0.4)\n",
    "# ax.axhline(2, color=\"black\", linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "# #ax.set_xlim(-0.25, 0.25)\n",
    "\n",
    "# plt.show()\n",
    "# #plt.savefig(\"../figures/LSCC-volcano-plot-v3.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-impute",
   "language": "python",
   "name": "deep-impute"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
